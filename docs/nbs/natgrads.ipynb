{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f89228",
   "metadata": {},
   "source": [
    "# Natural Gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcd16f",
   "metadata": {},
   "source": [
    "In this notebook we demonstrate how to implement natural gradients. \n",
    "\n",
    "As well explained in Salimbeni et al. (2018),\n",
    "\n",
    "\"The ordinary gradient turns out to be an unnatural direction to follow for variational inference since we are optimizing a distribution, rather than a set of pa- rameters directly. One way to define the gradient is the direction that achieves maximum change subject to a perturbation within a small euclidean ball. To see why the euclidean distance is an unnatural metric for probability distributions, consider the two Gaussians $\\mathcal{N}(0, 0.1)$ and $\\mathcal{N}(0, 0.2)$, compared to $\\mathcal{N}(0, 1000.1)$ and $\\mathcal{N}N(0,1000.2)$.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10376231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import jit, lax\n",
    "import optax as ox\n",
    "\n",
    "import gpjax as gpx\n",
    "from gpjax.abstractions import progress_bar_scan\n",
    "\n",
    "key = jr.PRNGKey(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b851a25",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7facf2",
   "metadata": {},
   "source": [
    "Generate dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "noise = 0.2\n",
    "\n",
    "x = jr.uniform(key=key, minval=-5.0, maxval=5.0, shape=(n,)).sort().reshape(-1, 1)\n",
    "f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "signal = f(x)\n",
    "y = signal + jr.normal(key, shape=signal.shape) * noise\n",
    "\n",
    "D = gpx.Dataset(X=x, y=y)\n",
    "xtest = jnp.linspace(-5.5, 5.5, 500).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57fb31",
   "metadata": {},
   "source": [
    "Intialise inducing points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6533b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jnp.linspace(-5.0, 5.0, 20).reshape(-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(x, y, \"o\", alpha=0.3)\n",
    "ax.plot(xtest, f(xtest))\n",
    "[ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1) for z_i in z]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c204b",
   "metadata": {},
   "source": [
    "# Model and variational inference strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4de494",
   "metadata": {},
   "source": [
    "Define model, variational family and variational inference strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpx.Gaussian(num_datapoints=n)\n",
    "kernel = gpx.RBF()\n",
    "prior = gpx.Prior(kernel=kernel)\n",
    "p =  prior * likelihood\n",
    "\n",
    "\n",
    "q = gpx.NaturalVariationalGaussian(prior=prior, inducing_inputs=z)\n",
    "svgp = gpx.StochasticVI(posterior=p, variational_family=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, trainables, constrainers, unconstrainers = gpx.initialise(svgp).unpack()\n",
    "params = gpx.transform(params, unconstrainers)\n",
    "\n",
    "loss_fn = jit(svgp.elbo(D, constrainers, negative=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e697ec",
   "metadata": {},
   "source": [
    "Get default parameters and transform these to the uncontrained space:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969b14e",
   "metadata": {},
   "source": [
    "# Natural gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793c24f",
   "metadata": {},
   "source": [
    "Define natural gradient and hyperparameter gradient functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_params, training_history = gpx.fit_natgrads(svgp,\n",
    "                                   params = params,\n",
    "                                   trainables = trainables,   \n",
    "                                   transformations = constrainers,\n",
    "                                   train_data = D,\n",
    "                                   n_iters = 10000,\n",
    "                                   batch_size=100,\n",
    "                                   key = jr.PRNGKey(42),\n",
    "                                   moment_optim = ox.sgd(1.0),\n",
    "                                   hyper_optim = ox.adam(1e-3),\n",
    "                                   ).unpack()\n",
    "\n",
    "learned_params = gpx.transform(learned_params, constrainers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdd41c",
   "metadata": {},
   "source": [
    "Plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff40778",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dist = q(learned_params)(xtest)\n",
    "predictive_dist = likelihood(latent_dist, learned_params)\n",
    "\n",
    "meanf = predictive_dist.mean()\n",
    "sigma = predictive_dist.stddev()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(x, y, \"o\", alpha=0.15, label=\"Training Data\", color=\"tab:gray\")\n",
    "ax.plot(xtest, meanf, label=\"Posterior mean\", color=\"tab:blue\")\n",
    "ax.fill_between(xtest.flatten(), meanf - sigma, meanf + sigma, alpha=0.3)\n",
    "[\n",
    "    ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1)\n",
    "    for z_i in learned_params[\"variational_family\"][\"inducing_inputs\"]\n",
    "]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1e2e3",
   "metadata": {},
   "source": [
    "# Natural gradients and sparse varational Gaussian process regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d29ec",
   "metadata": {},
   "source": [
    "As mentioned in Hensman et al 2013,  ....\n",
    "\n",
    "We demonstrate this now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995d1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "noise = 0.2\n",
    "\n",
    "x = jr.uniform(key=key, minval=-5.0, maxval=5.0, shape=(n,)).sort().reshape(-1, 1)\n",
    "f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "signal = f(x)\n",
    "y = signal + jr.normal(key, shape=signal.shape) * noise\n",
    "\n",
    "D = gpx.Dataset(X=x, y=y)\n",
    "\n",
    "xtest = jnp.linspace(-5.5, 5.5, 500).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec554e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jnp.linspace(-5.0, 5.0, 20).reshape(-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(x, y, \"o\", alpha=0.3)\n",
    "ax.plot(xtest, f(xtest))\n",
    "[ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1) for z_i in z]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee8115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpx.Gaussian(num_datapoints=n)\n",
    "kernel = gpx.RBF()\n",
    "prior = gpx.Prior(kernel=kernel)\n",
    "p =  prior * likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6640c071",
   "metadata": {},
   "source": [
    "We begin with natgrads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpjax.natural_gradients import natural_gradients\n",
    "\n",
    "q = gpx.NaturalVariationalGaussian(prior=prior, inducing_inputs=z)\n",
    "svgp = gpx.StochasticVI(posterior=p, variational_family=q)\n",
    "params, trainables, constrainers, unconstrainers = gpx.initialise(svgp).unpack()\n",
    "\n",
    "params = gpx.transform(params, unconstrainers)\n",
    "\n",
    "nat_grads_fn, hyper_grads_fn = natural_gradients(svgp, D, constrainers)\n",
    "\n",
    "moment_optim = ox.sgd(1.0)\n",
    "\n",
    "moment_state = moment_optim.init(params)\n",
    "\n",
    "# Natural gradients update:\n",
    "loss_val, loss_gradient = nat_grads_fn(params, trainables, D)\n",
    "print(loss_val)\n",
    "\n",
    "updates, moment_state = moment_optim.update(loss_gradient, moment_state, params)\n",
    "params = ox.apply_updates(params, updates)\n",
    "\n",
    "loss_val, _ = nat_grads_fn(params, trainables, D)\n",
    "\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c16824",
   "metadata": {},
   "source": [
    "Let us now run it for SGPR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpjax.parameters import build_identity\n",
    "\n",
    "q = gpx.CollapsedVariationalGaussian(prior=prior, likelihood=likelihood, inducing_inputs=z)\n",
    "sgpr = gpx.CollapsedVI(posterior=p, variational_family=q)\n",
    "\n",
    "params, trainables, constrainers, unconstrainers = gpx.initialise(svgp).unpack()\n",
    "\n",
    "params = gpx.transform(params, unconstrainers)\n",
    "\n",
    "loss_fn = sgpr.elbo(D, constrainers, negative=True)\n",
    "\n",
    "loss_val = loss_fn(params)\n",
    "\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae1c03",
   "metadata": {},
   "source": [
    "The discrepancy is due to the quadrature approximation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
