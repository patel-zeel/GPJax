{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ac6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f89228",
   "metadata": {},
   "source": [
    "# Natural Gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10376231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import jit, lax\n",
    "import optax as ox\n",
    "\n",
    "import gpjax as gpx\n",
    "from gpjax.natural_gradients import natural_gradients\n",
    "from gpjax.abstractions import progress_bar_scan\n",
    "\n",
    "#Set seed for reproducibility:\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "key = jr.PRNGKey(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b851a25",
   "metadata": {},
   "source": [
    "# Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7facf2",
   "metadata": {},
   "source": [
    "Generate dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "noise = 0.2\n",
    "\n",
    "x = jr.uniform(key=key, minval=-5.0, maxval=5.0, shape=(n,)).sort().reshape(-1, 1)\n",
    "f = lambda x: jnp.sin(4 * x) + jnp.cos(2 * x)\n",
    "signal = f(x)\n",
    "y = signal + jr.normal(key, shape=signal.shape) * noise\n",
    "\n",
    "D = gpx.Dataset(X=x, y=y)\n",
    "Dbatched = D.cache().repeat().shuffle(D.n).batch(batch_size=128).prefetch(buffer_size=1)\n",
    "\n",
    "xtest = jnp.linspace(-5.5, 5.5, 500).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af57fb31",
   "metadata": {},
   "source": [
    "Intialise inducing points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6533b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = jnp.linspace(-5.0, 5.0, 100).reshape(-1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(x, y, \"o\", alpha=0.3)\n",
    "ax.plot(xtest, f(xtest))\n",
    "[ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1) for z_i in z]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664c204b",
   "metadata": {},
   "source": [
    "# Model and variational inference strategy:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4de494",
   "metadata": {},
   "source": [
    "Define model, variational family and variational inference strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpx.Gaussian(num_datapoints=n)\n",
    "kernel = gpx.RBF()\n",
    "prior = gpx.Prior(kernel=kernel)\n",
    "p =  prior * likelihood\n",
    "\n",
    "\n",
    "q = gpx.NaturalVariationalGaussian(prior=prior, inducing_inputs=z)\n",
    "svgp = gpx.StochasticVI(posterior=p, variational_family=q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e697ec",
   "metadata": {},
   "source": [
    "Get default parameters and transform these to the uncontrained space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe96023",
   "metadata": {},
   "outputs": [],
   "source": [
    "params, trainables, constrainers, unconstrainers = gpx.initialise(svgp)\n",
    "\n",
    "params = gpx.transform(params, unconstrainers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969b14e",
   "metadata": {},
   "source": [
    "# Natural gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793c24f",
   "metadata": {},
   "source": [
    "Define natural gradient and hyperparameter gradient functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_grads_fn, hyper_grads_fn = natural_gradients(svgp, D, constrainers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf5e7a",
   "metadata": {},
   "source": [
    "Run optimisation loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88917f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimisation example:\n",
    "\n",
    "n_iters = 10000\n",
    "log_rate = 10\n",
    "train_data = Dbatched\n",
    "\n",
    "\n",
    "#Define optimisers:\n",
    "adam = ox.adam(1e-3) #<- hyperparameters\n",
    "sgd = ox.sgd(1e-3)   #<- for natgrads\n",
    " \n",
    "\n",
    "sgd_state = sgd.init(params)\n",
    "adam_state = adam.init(params)\n",
    "\n",
    "next_batch = train_data.get_batcher()\n",
    "\n",
    "# Optimisation step:\n",
    "@progress_bar_scan(n_iters, log_rate)\n",
    "def step(params_opt_state, i):\n",
    "    params, sgd_state, adam_state = params_opt_state\n",
    "    batch = next_batch()\n",
    "    \n",
    "    # Natural gradients update:\n",
    "    loss_val, loss_gradient = nat_grads_fn(params, trainables, batch)\n",
    "    updates, opt_state = sgd.update(loss_gradient, sgd_state, params)\n",
    "    params = ox.apply_updates(params, updates)\n",
    "    \n",
    "    \n",
    "    # Hyperparameters update:\n",
    "    loss_val, loss_gradient = hyper_grads_fn(params, trainables, batch)\n",
    "    updates, adam_state = adam.update(loss_gradient, adam_state, params)\n",
    "    params = ox.apply_updates(params, updates)\n",
    "    \n",
    "    \n",
    "    params_opt_state = params, sgd_state, adam_state\n",
    "    \n",
    "    \n",
    "    return params_opt_state, loss_val\n",
    " \n",
    "    \n",
    "# Optimisation loop:\n",
    "(params, _, _), _ = lax.scan(step, (params, sgd_state, adam_state), jnp.arange(n_iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcdd41c",
   "metadata": {},
   "source": [
    "Plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff40778",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_params = gpx.transform(params, constrainers)\n",
    "\n",
    "latent_dist = q(learned_params)(xtest)\n",
    "predictive_dist = likelihood(latent_dist, learned_params)\n",
    "\n",
    "meanf = predictive_dist.mean()\n",
    "sigma = predictive_dist.stddev()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.plot(x, y, \"o\", alpha=0.15, label=\"Training Data\", color=\"tab:gray\")\n",
    "ax.plot(xtest, meanf, label=\"Posterior mean\", color=\"tab:blue\")\n",
    "ax.fill_between(xtest.flatten(), meanf - sigma, meanf + sigma, alpha=0.3)\n",
    "[\n",
    "    ax.axvline(x=z_i, color=\"black\", alpha=0.3, linewidth=1)\n",
    "    for z_i in learned_params[\"variational_family\"][\"inducing_inputs\"]\n",
    "]\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7eb1cfec58eecaa2e5422163254bd25a3275ed109df9a51c3c95d775723db6f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
